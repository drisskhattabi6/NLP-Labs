The lab consisted of two parts: Language Modeling for Regression and Language Modeling for Classification. I employed the provided datasets, applied preprocessing steps, and experimented with various models using different encoding techniques.

For regression, Support Vector Regression (SVR) performed reasonably well, followed by Linear Regression and Decision Tree. However, for classification, Support Vector Classifier (SVC) outperformed other models, showing the highest accuracy and F1 score. Naive Bayes and Logistic Regression also showed decent performance, while AdaBoost performed slightly lower.

Overall, the lab provided a comprehensive hands-on experience with NLP tasks, reinforcing my understanding of preprocessing techniques, model training, and evaluation in the context of text data analysis.
